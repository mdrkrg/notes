---
tags:
  - DataScience
  - SJTU-Statistics
---
4.1 数学期望
===
## 数学期望的概念
### 离散型随机变量的期望
设**离散型**随机变量 $X$ 的分布律为

$$\begin{array}{c|ccccc}
\hline \quad X \quad &  x_{1}  &  x_{2}  &  \cdots  &  x_{k}  &  \ldots  \\
\hline P  &  p_{1}  &  p_{2}  &  \ldots  &  p_{k}  &  \cdots  \\
\hline
\end{array}$$

若级数 $\displaystyle\sum_{k=1}^{+\infty} x_{k} p_{k}$ 绝对收敛, 即 $\displaystyle\sum_{k=1}^{+\infty}\left|x_{k}\right| p_{k}<+\infty$, 则随机变量 $X$ 的**数学期望** (**均值**) 为

$$E(X) = \sum_{k=1}^{+\infty} x_{k} p_{k}$$
- 若级数不绝对收敛，则数学期望不存在

### 连续型随机变量的期望
设 $X$ 为**连续型**随机变量, 其概率密度为 $f(x)$

若 $\displaystyle\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$ 绝对收敛, 即 $\displaystyle\int_{-\infty}^{+\infty}|x| f(x) \mathrm{d} x<+\infty$, 则随机变量 $X$ 的**数学期望** (**均值**) 为
$$\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$$
- 若积分不绝对收敛，则数学期望不存在

> [!tip] 对于联合概率分布的单变量期望
> 先求出边缘概率分布 
> $$f_X(x) = F'_X(x) = \int_{-\infty}^{+\infty}f(x,y)\,\mathrm dy$$
> 再利用公式求出 $E(X)$

### 数学期望的性质
#### 存在性充要条件
设 $X$ 是任意随机变量, 则 $X$ 的数学期望存在的充要条件是
$$E(|\,X\,|)<+\infty$$
- 有界收敛
#### 有序性
设 $X,Y$ 是任意两个数学期望存在的随机变量, 且 $X\le Y$, 则
$$E(X) \le E(Y)$$

若存在数 $a$ 使得 $P(X\ge a) = 1$, 则
$$E(X)\ge a$$

若存在数 $b$ 使得 $P(X\le b) = 1$, 则
$$E(X)\le b$$
#### 常数的数学期望
设 $C$ 为常数, 则 $E(C) = C$
#### ==线性性==
设 $X$ 是任意满足 $E(|\,X\,|)<+\infty$ 的随机变量, $C$ 是任意常数, 则
$$E(C X)=C E(X)$$

设 $X,Y$ 是**任意**两个数学期望存在的随机变量, 则 $X+Y$ 的数学期望也存在, 且
$$E(X+Y)=E(X)+E(Y)$$
- 可适用于任意线性组合

#### 正向可乘性
设 $X,Y$ 是**相互独立**的两个数学期望存在的随机变量, 则 $XY$ 的数学期望也存在, 且
$$E(X Y)=E(X)\,E(Y)$$
- 逆命题不成立
#### 柯西－施瓦茨不等式
$$E^{2}(X Y) \leq E\left(X^{2}\right) E\left(Y^{2}\right)$$
当 $E\left(X^{2}\right)>0,E\left(Y^{2}\right)>0$, iff $P\left(Y=t_{0} X\right)=1$ 时, 等式成立

## 随机变量函数的数学期望
本质上是对变量的函数值进行期望运算

### 一维随机变量
设 $X$ 为随机变量, $Y=g(X)$, 其中 $g(x)$ 是一个确定函数

#### 离散型
设 $X$ 为离散型随机变量, 其分布律为 $P\left(X=x_{k}\right)=p_{k},k=1,2,\cdots$,

若级数 $\displaystyle\sum_{k=1}^{+\infty} g\left(x_{k}\right) p_{k}$ 绝对收敛, 则
$$E(Y)=E\big(g(X)\big)=\sum_{k=1}^{+\infty} g\left(x_{k}\right)\, p_{k}$$

#### 连续型
设 $X$ 为连续型随机变量, 其概率密度为 $f(x)$,

若积分 $\displaystyle\int_{-\infty}^{+\infty} g(x) f(x) \mathrm{d} x$ 绝对收敛, 则
$$E(Y)=E\big(g(X)\big)=\int_{-\infty}^{+\infty} g(x)\,f(x)\, \mathrm{d} x$$
### 二维随机变量
设 $X,Y$ 为随机变量, $Z=g(X,Y)$, 其中 $g(x,y)$ 是一个确定函数

#### 离散型
设 $(X,Y)$ 为离散型随机变量, 其分布律为 $P\left(X=x_{i}, Y = y_j\right)=p_{ij},i,j=1,2,\cdots$,

若级数 $\displaystyle\sum_{i=1}^{+\infty} \sum_{j=1}^{+\infty} g\left(x_{i},y_{j}\right) p_{i j}$ 绝对收敛, 则
$$E(Z)=E\big(g(X,Y)\big)=\sum_{i=1}^{+\infty} \sum_{j=1}^{+\infty} g\left(x_{i},y_{j}\right)\,p_{i j}$$

#### 连续型
设 $(X,Y)$ 为连续型随机变量, 其联合概率密度为 $f(x,y)$, 
若积分 $\displaystyle\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x,y) f(x,y) \,\mathrm{d} x \, \mathrm{d} y$ 绝对收敛, 
$$E(Z)=E\big(g(X,Y)\big)=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x,y) \, f(x,y) \,\mathrm{d} x \,\mathrm{d} y$$
